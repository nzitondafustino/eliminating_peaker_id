{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b01b6f4-9007-45b3-b855-4a909821748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install speechbrain\n",
    "# !pip install ruamel_yaml\n",
    "# !pip install --upgrade ruamel.yaml --ignore-installed ruamel.yaml\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html \n",
    "# self.conv = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "# kernel_size=kernel_size, stride=stride, dilation=dilation, padding=padding),\n",
    "# PixelShuffle(upscale_factor),\n",
    "# nn.InstanceNorm2d(num_features=out_channels)) \n",
    "# !pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c8bedf4-d86c-4eee-ac18-ccc0b32f1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speechbrain as sb\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from speechbrain.pretrained import EncoderDecoderASR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b6cd9f-3ecf-42e4-a48e-114e1320ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", \n",
    "                                       savedir=\"pretrained_models/asr-crdnn-rnnlm-librispeech\",run_opts={\"device\":\"cuda\"},freeze_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3daa6ad5-7592-4656-8cc2-fd5358ef85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.hparams.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3973b9a9-d5e7-41a4-9f3c-fd5c30b9e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = LIBRISPEECH(\".\", url= 'dev-clean',download=True)\n",
    "train_dataset = LIBRISPEECH(\".\",download=True)\n",
    "test_dataset = LIBRISPEECH(\".\",url= 'test-clean',download=True)\n",
    "# dataset1 = MNIST(\".\",download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174612b5-a317-472b-a821-119ec178e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    \"\"\"waveform, sample_rate, transcript, speaker_id\"\"\"\n",
    "    waveforms = [b[0].permute([1,0]) for b in batch]\n",
    "    waveforms = pad_sequence(waveforms,batch_first=True)\n",
    "    waveforms = waveforms.squeeze()\n",
    "    input_len = torch.FloatTensor([b[0].shape[1] for b in batch])\n",
    "    input_len /= torch.max(input_len)\n",
    "    sampling_rates = torch.FloatTensor([b[1] for b in batch])\n",
    "    transcript = [b[2] for b in batch]\n",
    "    speaker_id = torch.LongTensor([b[3] for b in batch])\n",
    "    \n",
    "    return waveforms,input_len,sampling_rates,transcript,speaker_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0cc0cac-e7bc-4288-9ef9-37a2a10de96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataLoader = DataLoader(train_dataset,batch_size=5,shuffle=True,collate_fn=collate)\n",
    "val_dataLoader = DataLoader(val_dataset,batch_size=5,shuffle=False,collate_fn=collate)\n",
    "test_dataLoader = DataLoader(test_dataset,batch_size=5,shuffle=False,collate_fn=collate)\n",
    "# train_dataloader = DataLoader(dataset1,batch_size=5,shuffle=True,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b4e20c-59da-4295-ba1a-8c9c751a0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(train_dataLoader,start=1):\n",
    "#     print(speaker_id)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c097f-109c-40fe-93d1-867c0423d421",
   "metadata": {},
   "source": [
    "# highwat network\n",
    "- adopted from https://github.com/kefirski/pytorch_Highway.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17baf8f3-66f0-452e-aba0-b924f14c4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(nn.Module):\n",
    "    def __init__(self, size, num_layers, f):\n",
    "\n",
    "        super(Highway, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.nonlinear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
    "\n",
    "        self.linear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
    "\n",
    "        self.gate = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
    "\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            :param x: tensor with shape of [batch_size, size]\n",
    "            :return: tensor with shape of [batch_size, size]\n",
    "            applies σ(x) ⨀ (f(G(x))) + (1 - σ(x)) ⨀ (Q(x)) transformation | G and Q is affine transformation,\n",
    "            f is non-linear transformation, σ(x) is affine transformation with sigmoid non-linearition\n",
    "            and ⨀ is element-wise multiplication\n",
    "            \"\"\"\n",
    "\n",
    "        for layer in range(self.num_layers):\n",
    "            gate = torch.sigmoid(self.gate[layer](x))\n",
    "\n",
    "            nonlinear = self.f(self.nonlinear[layer](x))\n",
    "            linear = self.linear[layer](x)\n",
    "\n",
    "            x = gate * nonlinear + (1 - gate) * linear\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42fb0e31-a7c9-4e3e-a02f-f909fa198229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecsReconstruction(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_features,num_blocks,hidden_size,out_feature=40):\n",
    "        super().__init__()\n",
    "        self.input_features = input_features\n",
    "        self.num_blocks = num_blocks\n",
    "        self.out_feature = out_feature\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_features,hidden_size) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.highway = Highway(hidden_size,num_blocks,nn.ReLU())\n",
    "        self.linear2 = nn.Linear(hidden_size,out_feature)\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.highway(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6013450-9fdf-4d0c-9bdc-70bb263375f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = SpecsReconstruction(2560,5,100,40).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07308c23-e28d-4d49-b14d-3c07dd2af9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.L1Loss()\n",
    "# optimizer = torch.optim.Adam(h0.parameters(),lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=2)\n",
    "# epochs = 30\n",
    "path = \"h0_states.pth\"\n",
    "def load_model_parameter(path):\n",
    "    try:\n",
    "        print(\"Loading states\")\n",
    "        state = torch.load(path)\n",
    "        start_epoch = state[\"epoch\"]\n",
    "        train_losses = state[\"train_losses\"]\n",
    "        val_losses = state[\"val_losses\"]\n",
    "        model_dict = state[\"model_dict\"]\n",
    "        optimizer = state[\"optimizer\"]\n",
    "        scheduler = state[\"scheduler\"]\n",
    "        print(\"successifully loaded states\")\n",
    "        return start_epoch,train_losses,val_losses,model_dict,optimizer,scheduler\n",
    "    except:\n",
    "        print(\"failed to load states\")\n",
    "        return None\n",
    "\n",
    "def save_model_parameters(path,state_dict):\n",
    "    torch.save(state_dict,path)\n",
    "    print(\"states at {} epoch saved\".format(state_dict[\"epoch\"]))\n",
    "    \n",
    "states = load_model_parameter(path)\n",
    "if states is not None:\n",
    "    start_epoch,train_losses,val_losses,model_dict,optimizer_dict,scheduler_dict = states\n",
    "    h0.load_state_dict(model_dict)\n",
    "    optimizer.load_state_dict(optimizer_dict)\n",
    "    scheduler.load_state_dict(scheduler_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9778e-bc64-447d-b202-08a43efcc17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "min_loss = np.Infinity\n",
    "\n",
    "for i in range(epochs):\n",
    "    t = []\n",
    "    l = []\n",
    "    h0.train()\n",
    "    for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(train_dataLoader,start=1):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            block_0 = encoder.model.CNN.block_0(targets)\n",
    "        block_0 = block_0.reshape(block_0.shape[0],block_0.shape[1],-1)\n",
    "        out = h0(block_0)\n",
    "        loss = criterion(targets,out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (j+1) % 100 == 0:\n",
    "            print(\"epoch:{}/{}\".format(i+1,epochs,j))\n",
    "        t.append(loss.item())\n",
    "    av_t = sum(t)/len(t)\n",
    "    print(\"epoch:{}/{},Train loss:{}\".format(i+1,epochs,av_t))\n",
    "    train_loss.append(av_t)\n",
    "    del waveform\n",
    "    del input_len\n",
    "    # validation loop\n",
    "    h0.eval()\n",
    "    for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(val_dataLoader,start=1):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            block_0 = encoder.model.CNN.block_0(targets)\n",
    "            block_0 = block_0.reshape(block_0.shape[0],block_0.shape[1],-1)\n",
    "            out = h0(block_0)\n",
    "            loss = criterion(targets,out)\n",
    "            if (j+1) % 100 == 0:\n",
    "                print(\"epoch:{}/{}\".format(i+1,epochs,j))\n",
    "            l.append(loss.item())\n",
    "    av_l = sum(l)/len(l)\n",
    "    print(\"epoch:{}/{},Val loss:{}\".format(i+1,epochs,av_l))\n",
    "    val_loss.append(av_l)\n",
    "    if av_l < min_loss:\n",
    "        min_loss = av_l\n",
    "        torch.save(h0,\"best_model_0\")\n",
    "        \n",
    "    state_dict = {\n",
    "    \"epoch\":i,\n",
    "    \"train_losses\":train_loss,\n",
    "    \"val_losses\":val_loss,\n",
    "    \"model_dict\":h0.state_dict(),\n",
    "    \"optimizer\":optimizer.state_dict(),\n",
    "    \"scheduler\":scheduler.state_dict()\n",
    "    }\n",
    "    save_model_parameters(\"h0_states.pth\",state_dict)\n",
    "    scheduler.step(av_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842290a-987f-4ce3-9f22-f2cb318a56b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_1 = SpecsReconstruction(5120,5,100,40).cuda()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(h0_1.parameters(),lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=2)\n",
    "epochs = 30\n",
    "stretch = torchaudio.transforms.TimeStretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ab421-b56d-4acc-83bd-fbb55333a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"h0_1_states.pth\"\n",
    "def load_model_parameter(path):\n",
    "    try:\n",
    "        print(\"Loading states\")\n",
    "        state = torch.load(path)\n",
    "        start_epoch = state[\"epoch\"]\n",
    "        train_losses = state[\"train_losses\"]\n",
    "        val_losses = state[\"val_losses\"]\n",
    "        model_dict = state[\"model_dict\"]\n",
    "        optimizer = state[\"optimizer\"]\n",
    "        scheduler = state[\"scheduler\"]\n",
    "        print(\"successifully loaded states\")\n",
    "        return start_epoch,train_losses,val_losses,model_dict,optimizer,scheduler\n",
    "    except:\n",
    "        print(\"failed to load states\")\n",
    "        return None\n",
    "\n",
    "def save_model_parameters(path,state_dict):\n",
    "    torch.save(state_dict,path)\n",
    "    print(\"states at {} epoch saved\".format(state_dict[\"epoch\"]))\n",
    "    \n",
    "states = load_model_parameter(path)\n",
    "if states is not None:\n",
    "    start_epoch,train_losses,val_losses,model_dict,optimizer_dict,scheduler_dict = states\n",
    "    h0_1.load_state_dict(model_dict)\n",
    "    optimizer.load_state_dict(optimizer_dict)\n",
    "    scheduler.load_state_dict(scheduler_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dade52-4616-4a92-8423-1819b6b9bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "min_loss = np.Infinity\n",
    "\n",
    "for i in range(start_epoch,epochs):\n",
    "    t = []\n",
    "    l = []\n",
    "    h0_1.train()\n",
    "    for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(train_dataLoader,start=1):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            conv_1 = encoder.model.CNN.block_0.conv_1(targets)\n",
    "            norm_1 = encoder.model.CNN.block_0.norm_1(conv_1)\n",
    "            norm_1 =  norm_1.reshape( norm_1.shape[0], norm_1.shape[1],-1)\n",
    "        out = h0_1(norm_1)\n",
    "        loss = criterion(targets,out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (j+1) % 100 == 0:\n",
    "            print(\"epoch:{}/{}\".format(i+1,epochs,j))\n",
    "        t.append(loss.item())\n",
    "    av_t = sum(t)/len(t)\n",
    "    print(\"epoch:{}/{},Train loss:{}\".format(i+1,epochs,av_t))\n",
    "    train_loss.append(av_t)\n",
    "    del waveform\n",
    "    del input_len\n",
    "    # validation loop\n",
    "    h0_1.eval()\n",
    "    for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(val_dataLoader,start=1):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            conv_1 = encoder.model.CNN.block_0.conv_1(targets)\n",
    "            norm_1 = encoder.model.CNN.block_0.norm_1(conv_1)\n",
    "            norm_1 =  norm_1.reshape( norm_1.shape[0], norm_1.shape[1],-1)\n",
    "            out = h0_1(norm_1)\n",
    "            loss = criterion(targets,out)\n",
    "            if (j+1) % 100 == 0:\n",
    "                print(\"epoch:{}/{}\".format(i+1,epochs,j))\n",
    "            l.append(loss.item())\n",
    "    av_l = sum(l)/len(l)\n",
    "    print(\"epoch:{}/{},Val loss:{}\".format(i+1,epochs,av_l))\n",
    "    val_loss.append(av_l)\n",
    "    if av_l < min_loss:\n",
    "        min_loss = av_l\n",
    "        torch.save(h0_1,\"best_model_01\")\n",
    "        \n",
    "    state_dict = {\n",
    "    \"epoch\":i,\n",
    "    \"train_losses\":train_loss,\n",
    "    \"val_losses\":val_loss,\n",
    "    \"model_dict\":h0_1.state_dict(),\n",
    "    \"optimizer\":optimizer.state_dict(),\n",
    "    \"scheduler\":scheduler.state_dict()\n",
    "    }\n",
    "    save_model_parameters(\"h0_1_states.pth\",state_dict)\n",
    "    scheduler.step(av_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71068177-49a6-4987-85ce-43779fa56c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del h0\n",
    "h1 = SpecsReconstruction(2560,5,100,40).cuda()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(h1.parameters(),lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=2)\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f34396-de68-4106-8f99-0acd6fa4541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "min_loss = np.Infinity\n",
    "\n",
    "for i in range(epochs):\n",
    "    t = []\n",
    "    l = []\n",
    "    h1.train()\n",
    "    for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(train_dataLoader,start=1):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            block_0 = encoder.model.CNN.block_0(targets)\n",
    "            block_1 = encoder.model.CNN.block_1( block_0)\n",
    "            block_1 = block_1.reshape(block_1.shape[0],block_1.shape[1],-1)\n",
    "        out = h1(block_1)\n",
    "        loss = criterion(targets,out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (j+1) % 100 == 0:inputs\n",
    "            print(\"epoch:{}/{}\".format(i+1,epochs,j))\n",
    "        t.append(loss.item())\n",
    "    av_t = sum(t)/len(t)\n",
    "    print(\"epoch:{}/{},Train loss:{}\".format(i+1,epochs,av_t))\n",
    "    train_loss.append(av_t)\n",
    "    del waveform\n",
    "    del input_len\n",
    "    # validation loop\n",
    "    h1.eval()\n",
    "    for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(val_dataLoader,start=1):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            block_0 = encoder.model.CNN.block_0(targets)\n",
    "            block_1 = encoder.model.CNN.block_1(block_0)\n",
    "            block_1 = block_1.reshape(block_1.shape[0],block_1.shape[1],-1)\n",
    "            out = h1(block_1)\n",
    "            loss = criterion(targets,out)\n",
    "            if (j+1) % 100 == 0:\n",
    "                print(\"epoch:{}/{}\".format(i+1,epochs,j))\n",
    "            l.append(loss.item())\n",
    "    av_l = sum(l)/len(l)\n",
    "    print(\"epoch:{}/{},Val loss:{}\".format(i+1,epochs,av_l))\n",
    "    val_loss.append(av_l)\n",
    "    if av_l < min_loss:\n",
    "        min_loss = av_l\n",
    "        torch.save(h1,\"best_model_1\")\n",
    "        \n",
    "    state_dict = {\n",
    "    \"epoch\":i,\n",
    "    \"train_losses\":train_loss,\n",
    "    \"val_losses\":val_loss,\n",
    "    \"model_dict\":h1.state_dict(),\n",
    "    \"optimizer\":optimizer.state_dict(),\n",
    "    \"scheduler\":scheduler.state_dict()\n",
    "    }\n",
    "    save_model_parameters(\"h1_states.pth\",state_dict)\n",
    "    scheduler.step(av_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395248c0-c873-40f0-be36-92648abc441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_1 = SpecsReconstruction(5120,5,100,40).cuda()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(h1_1.parameters(),lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=2)\n",
    "epochs = 30\n",
    "stretch = torchaudio.transforms.TimeStretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f158d2-2bec-4ad6-9531-97502f14d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"h1_1_states.pth\"\n",
    "def load_model_parameter(path):\n",
    "    try:\n",
    "        print(\"Loading states\")\n",
    "        state = torch.load(path)\n",
    "        start_epoch = state[\"epoch\"]\n",
    "        train_losses = state[\"train_losses\"]\n",
    "        val_losses = state[\"val_losses\"]\n",
    "        model_dict = state[\"model_dict\"]\n",
    "        optimizer = state[\"optimizer\"]\n",
    "        scheduler = state[\"scheduler\"]\n",
    "        print(\"successifully loaded states\")\n",
    "        return start_epoch,train_losses,val_losses,model_dict,optimizer,scheduler\n",
    "    except:\n",
    "        print(\"failed to load states\")\n",
    "        return None\n",
    "\n",
    "def save_model_parameters(path,state_dict):\n",
    "    torch.save(state_dict,path)\n",
    "    print(\"states at {} epoch saved\".format(state_dict[\"epoch\"]))\n",
    "    \n",
    "states = load_model_parameter(path)\n",
    "if states is not None:\n",
    "    start_epoch,train_losses,val_losses,model_dict,optimizer_dict,scheduler_dict = states\n",
    "    h1_1.load_state_dict(model_dict)\n",
    "    optimizer.load_state_dict(optimizer_dict)\n",
    "    scheduler.load_state_dict(scheduler_dict)\n",
    "else:\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9fb7b5-40cb-4e57-a19e-4dea4bdd5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "min_loss = np.Infinity\n",
    "\n",
    "for i in range(start_epoch,epochs):\n",
    "    t = []\n",
    "    l = []\n",
    "    h1_1.train()\n",
    "    for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(train_dataLoader,start=1):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            block_0 = encoder.model.CNN.block_0(targets)\n",
    "            conv_1 = encoder.model.CNN.block_1.conv_1(block_0)\n",
    "            norm_1 = encoder.model.CNN.block_1.norm_1(conv_1)\n",
    "            norm_1 =  norm_1.reshape( norm_1.shape[0], norm_1.shape[1],-1)\n",
    "        out = h1_1(norm_1)\n",
    "        loss = criterion(targets,out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (j+1) % 100 == 0:\n",
    "            print(\"epoch:{}/{}\".format(i+1,epochs,j))\n",
    "        t.append(loss.item())\n",
    "    av_t = sum(t)/len(t)\n",
    "    print(\"epoch:{}/{},Train loss:{}\".format(i+1,epochs,av_t))\n",
    "    train_loss.append(av_t)\n",
    "    del waveform\n",
    "    del input_len\n",
    "    # validation loop\n",
    "    h1_1.eval()\n",
    "    for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(val_dataLoader,start=1):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            block_0 = encoder.model.CNN.block_0(targets)\n",
    "            conv_1 = encoder.model.CNN.block_1.conv_1(block_0)\n",
    "            norm_1 = encoder.model.CNN.block_1.norm_1(conv_1)\n",
    "            norm_1 =  norm_1.reshape( norm_1.shape[0], norm_1.shape[1],-1)\n",
    "            out = h1_1(norm_1)\n",
    "            loss = criterion(targets,out)\n",
    "            if (j+1) % 100 == 0:\n",
    "                print(\"epoch:{}/{}\".format(i+1,epochs,j))\n",
    "            l.append(loss.item())\n",
    "    av_l = sum(l)/len(l)\n",
    "    print(\"epoch:{}/{},Val loss:{}\".format(i+1,epochs,av_l))\n",
    "    val_loss.append(av_l)\n",
    "    if av_l < min_loss:\n",
    "        min_loss = av_l\n",
    "        torch.save(h1_1,\"best_model_11\")\n",
    "        \n",
    "    state_dict = {\n",
    "    \"epoch\":i,\n",
    "    \"train_losses\":train_loss,\n",
    "    \"val_losses\":val_loss,\n",
    "    \"model_dict\":h1_1.state_dict(),\n",
    "    \"optimizer\":optimizer.state_dict(),\n",
    "    \"scheduler\":scheduler.state_dict()\n",
    "    }\n",
    "    save_model_parameters(\"h1_1_states.pth\",state_dict)\n",
    "    scheduler.step(av_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad0911-795c-4ee5-9da8-1822ee5fc610",
   "metadata": {},
   "source": [
    "## Transcription class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b024b3a-bc70-4761-86b2-ce6425e5a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transcribe:\n",
    "    def __init__(self):\n",
    "        self.model = model\n",
    "    def __call__(self,x,lens):\n",
    "        return self.forward(x,lens)\n",
    "    def forward(self,x,lens):\n",
    "        predicted_words = []\n",
    "        with torch.no_grad():\n",
    "            out = self.model.hparams.encoder.model(x)\n",
    "            out,_ = self.model.hparams.decoder(out,lens)\n",
    "            predicted_words = [self.model.hparams.tokenizer.decode_ids(o) for o in out]\n",
    "            return predicted_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cb99c-ad1f-42ee-9769-28a85c93c494",
   "metadata": {},
   "source": [
    "### Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed4fc6b7-445e-40c5-898f-f407a7e23304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h0 = SpecsReconstruction(2560,5,100,40).cuda()\n",
    "h0 = torch.load(\"best_model_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd02532a-f4ec-41b1-81c9-2ff9a89c88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe = Transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40cba321-fd01-4362-8eef-b4d8f3282f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/524\n",
      "1/524\n",
      "2/524\n",
      "3/524\n",
      "4/524\n",
      "5/524\n",
      "6/524\n",
      "7/524\n",
      "8/524\n",
      "9/524\n",
      "10/524\n",
      "11/524\n",
      "12/524\n",
      "13/524\n",
      "14/524\n",
      "15/524\n",
      "16/524\n",
      "17/524\n",
      "18/524\n",
      "19/524\n",
      "20/524\n",
      "21/524\n",
      "22/524\n",
      "23/524\n",
      "24/524\n",
      "25/524\n",
      "26/524\n",
      "27/524\n",
      "28/524\n",
      "29/524\n",
      "30/524\n",
      "31/524\n",
      "32/524\n",
      "33/524\n",
      "34/524\n",
      "35/524\n",
      "36/524\n",
      "37/524\n",
      "38/524\n",
      "39/524\n",
      "40/524\n",
      "41/524\n",
      "42/524\n",
      "43/524\n",
      "44/524\n",
      "45/524\n",
      "46/524\n",
      "47/524\n",
      "48/524\n",
      "49/524\n",
      "50/524\n",
      "51/524\n",
      "52/524\n",
      "53/524\n",
      "54/524\n",
      "55/524\n",
      "56/524\n",
      "57/524\n",
      "58/524\n",
      "59/524\n",
      "60/524\n",
      "61/524\n",
      "62/524\n",
      "63/524\n",
      "64/524\n",
      "65/524\n",
      "66/524\n",
      "67/524\n",
      "68/524\n",
      "69/524\n",
      "70/524\n",
      "71/524\n",
      "72/524\n",
      "73/524\n",
      "74/524\n",
      "75/524\n",
      "76/524\n",
      "77/524\n",
      "78/524\n",
      "79/524\n",
      "80/524\n",
      "81/524\n",
      "82/524\n",
      "83/524\n",
      "84/524\n",
      "85/524\n",
      "86/524\n",
      "87/524\n",
      "88/524\n",
      "89/524\n",
      "90/524\n",
      "91/524\n",
      "92/524\n",
      "93/524\n",
      "94/524\n",
      "95/524\n",
      "96/524\n",
      "97/524\n",
      "98/524\n",
      "99/524\n",
      "100/524\n",
      "101/524\n",
      "102/524\n",
      "103/524\n",
      "104/524\n",
      "105/524\n",
      "106/524\n",
      "107/524\n",
      "108/524\n",
      "109/524\n",
      "110/524\n",
      "111/524\n",
      "112/524\n",
      "113/524\n",
      "114/524\n",
      "115/524\n",
      "116/524\n",
      "117/524\n",
      "118/524\n",
      "119/524\n",
      "120/524\n",
      "121/524\n",
      "122/524\n",
      "123/524\n",
      "124/524\n",
      "125/524\n",
      "126/524\n",
      "127/524\n",
      "128/524\n",
      "129/524\n",
      "130/524\n",
      "131/524\n",
      "132/524\n",
      "133/524\n",
      "134/524\n",
      "135/524\n",
      "136/524\n",
      "137/524\n",
      "138/524\n",
      "139/524\n",
      "140/524\n",
      "141/524\n",
      "142/524\n",
      "143/524\n",
      "144/524\n",
      "145/524\n",
      "146/524\n",
      "147/524\n",
      "148/524\n",
      "149/524\n",
      "150/524\n",
      "151/524\n",
      "152/524\n",
      "153/524\n",
      "154/524\n",
      "155/524\n",
      "156/524\n",
      "157/524\n",
      "158/524\n",
      "159/524\n",
      "160/524\n",
      "161/524\n",
      "162/524\n",
      "163/524\n",
      "164/524\n",
      "165/524\n",
      "166/524\n",
      "167/524\n",
      "168/524\n",
      "169/524\n",
      "170/524\n",
      "171/524\n",
      "172/524\n",
      "173/524\n",
      "174/524\n",
      "175/524\n",
      "176/524\n",
      "177/524\n",
      "178/524\n",
      "179/524\n",
      "180/524\n",
      "181/524\n",
      "182/524\n",
      "183/524\n",
      "184/524\n",
      "185/524\n",
      "186/524\n",
      "187/524\n",
      "188/524\n",
      "189/524\n",
      "190/524\n",
      "191/524\n",
      "192/524\n",
      "193/524\n",
      "194/524\n",
      "195/524\n",
      "196/524\n",
      "197/524\n",
      "198/524\n",
      "199/524\n",
      "200/524\n",
      "201/524\n",
      "202/524\n",
      "203/524\n",
      "204/524\n",
      "205/524\n",
      "206/524\n",
      "207/524\n",
      "208/524\n",
      "209/524\n",
      "210/524\n",
      "211/524\n",
      "212/524\n",
      "213/524\n",
      "214/524\n",
      "215/524\n",
      "216/524\n",
      "217/524\n",
      "218/524\n",
      "219/524\n",
      "220/524\n",
      "221/524\n",
      "222/524\n",
      "223/524\n",
      "224/524\n",
      "225/524\n",
      "226/524\n",
      "227/524\n",
      "228/524\n",
      "229/524\n",
      "230/524\n",
      "231/524\n",
      "232/524\n",
      "233/524\n",
      "234/524\n",
      "235/524\n",
      "236/524\n",
      "237/524\n",
      "238/524\n",
      "239/524\n",
      "240/524\n",
      "241/524\n",
      "242/524\n",
      "243/524\n",
      "244/524\n",
      "245/524\n",
      "246/524\n",
      "247/524\n",
      "248/524\n",
      "249/524\n",
      "250/524\n",
      "251/524\n",
      "252/524\n",
      "253/524\n",
      "254/524\n",
      "255/524\n",
      "256/524\n",
      "257/524\n",
      "258/524\n",
      "259/524\n",
      "260/524\n",
      "261/524\n",
      "262/524\n",
      "263/524\n",
      "264/524\n",
      "265/524\n",
      "266/524\n",
      "267/524\n",
      "268/524\n",
      "269/524\n",
      "270/524\n",
      "271/524\n",
      "272/524\n",
      "273/524\n",
      "274/524\n",
      "275/524\n",
      "276/524\n",
      "277/524\n",
      "278/524\n",
      "279/524\n",
      "280/524\n",
      "281/524\n",
      "282/524\n",
      "283/524\n",
      "284/524\n",
      "285/524\n",
      "286/524\n",
      "287/524\n",
      "288/524\n",
      "289/524\n",
      "290/524\n",
      "291/524\n",
      "292/524\n",
      "293/524\n",
      "294/524\n",
      "295/524\n",
      "296/524\n",
      "297/524\n",
      "298/524\n",
      "299/524\n",
      "300/524\n",
      "301/524\n",
      "302/524\n",
      "303/524\n",
      "304/524\n",
      "305/524\n",
      "306/524\n",
      "307/524\n",
      "308/524\n",
      "309/524\n",
      "310/524\n",
      "311/524\n",
      "312/524\n",
      "313/524\n",
      "314/524\n",
      "315/524\n",
      "316/524\n",
      "317/524\n",
      "318/524\n",
      "319/524\n",
      "320/524\n",
      "321/524\n",
      "322/524\n",
      "323/524\n",
      "324/524\n",
      "325/524\n",
      "326/524\n",
      "327/524\n",
      "328/524\n",
      "329/524\n",
      "330/524\n",
      "331/524\n",
      "332/524\n",
      "333/524\n",
      "334/524\n",
      "335/524\n",
      "336/524\n",
      "337/524\n",
      "338/524\n",
      "339/524\n",
      "340/524\n",
      "341/524\n",
      "342/524\n",
      "343/524\n",
      "344/524\n",
      "345/524\n",
      "346/524\n",
      "347/524\n",
      "348/524\n",
      "349/524\n",
      "350/524\n",
      "351/524\n",
      "352/524\n",
      "353/524\n",
      "354/524\n",
      "355/524\n",
      "356/524\n",
      "357/524\n",
      "358/524\n",
      "359/524\n",
      "360/524\n",
      "361/524\n",
      "362/524\n",
      "363/524\n",
      "364/524\n",
      "365/524\n",
      "366/524\n",
      "367/524\n",
      "368/524\n",
      "369/524\n",
      "370/524\n",
      "371/524\n",
      "372/524\n",
      "373/524\n",
      "374/524\n",
      "375/524\n",
      "376/524\n",
      "377/524\n",
      "378/524\n",
      "379/524\n",
      "380/524\n",
      "381/524\n",
      "382/524\n",
      "383/524\n",
      "384/524\n",
      "385/524\n",
      "386/524\n",
      "387/524\n",
      "388/524\n",
      "389/524\n",
      "390/524\n",
      "391/524\n",
      "392/524\n",
      "393/524\n",
      "394/524\n",
      "395/524\n",
      "396/524\n",
      "397/524\n",
      "398/524\n",
      "399/524\n",
      "400/524\n",
      "401/524\n",
      "402/524\n",
      "403/524\n",
      "404/524\n",
      "405/524\n",
      "406/524\n",
      "407/524\n",
      "408/524\n",
      "409/524\n",
      "410/524\n",
      "411/524\n",
      "412/524\n",
      "413/524\n",
      "414/524\n",
      "415/524\n",
      "416/524\n",
      "417/524\n",
      "418/524\n",
      "419/524\n",
      "420/524\n",
      "421/524\n",
      "422/524\n",
      "423/524\n",
      "424/524\n",
      "425/524\n",
      "426/524\n",
      "427/524\n",
      "428/524\n",
      "429/524\n",
      "430/524\n",
      "431/524\n",
      "432/524\n",
      "433/524\n",
      "434/524\n",
      "435/524\n",
      "436/524\n",
      "437/524\n",
      "438/524\n",
      "439/524\n",
      "440/524\n",
      "441/524\n",
      "442/524\n",
      "443/524\n",
      "444/524\n",
      "445/524\n",
      "446/524\n",
      "447/524\n",
      "448/524\n",
      "449/524\n",
      "450/524\n",
      "451/524\n",
      "452/524\n",
      "453/524\n",
      "454/524\n",
      "455/524\n",
      "456/524\n",
      "457/524\n",
      "458/524\n",
      "459/524\n",
      "460/524\n",
      "461/524\n",
      "462/524\n",
      "463/524\n",
      "464/524\n",
      "465/524\n",
      "466/524\n",
      "467/524\n",
      "468/524\n",
      "469/524\n",
      "470/524\n",
      "471/524\n",
      "472/524\n",
      "473/524\n",
      "474/524\n",
      "475/524\n",
      "476/524\n",
      "477/524\n",
      "478/524\n",
      "479/524\n",
      "480/524\n",
      "481/524\n",
      "482/524\n",
      "483/524\n",
      "484/524\n",
      "485/524\n",
      "486/524\n",
      "487/524\n",
      "488/524\n",
      "489/524\n",
      "490/524\n",
      "491/524\n",
      "492/524\n",
      "493/524\n",
      "494/524\n",
      "495/524\n",
      "496/524\n",
      "497/524\n",
      "498/524\n",
      "499/524\n",
      "500/524\n",
      "501/524\n",
      "502/524\n",
      "503/524\n",
      "504/524\n",
      "505/524\n",
      "506/524\n",
      "507/524\n",
      "508/524\n",
      "509/524\n",
      "510/524\n",
      "511/524\n",
      "512/524\n",
      "513/524\n",
      "514/524\n",
      "515/524\n",
      "516/524\n",
      "517/524\n",
      "518/524\n",
      "519/524\n",
      "520/524\n",
      "521/524\n",
      "522/524\n",
      "523/524\n"
     ]
    }
   ],
   "source": [
    "h0.eval()\n",
    "word_error_rate = 0\n",
    "for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(test_dataLoader):\n",
    "        waveform = waveform.cuda()\n",
    "        input_len = input_len.cuda()\n",
    "        with torch.no_grad():\n",
    "            specs = encoder.compute_features(waveform)\n",
    "            targets = encoder.normalize(specs,input_len)\n",
    "            block_0 = encoder.model.CNN.block_0(targets)\n",
    "            block_0 = block_0.reshape(block_0.shape[0],block_0.shape[1],-1)\n",
    "            out = h0(block_0)\n",
    "            trans = transcribe(out,input_len)\n",
    "            for i in range(len(trans)):\n",
    "                word_error_rate += wer(trans[i],transcript[i])\n",
    "            print(\"{}/{}\".format(j,len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d58a74b3-c4ea-4516-ad9d-b9f544ecd8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World error rate:0.06468178009155047\n"
     ]
    }
   ],
   "source": [
    "print(\"World error rate:{}\".format(word_error_rate/5/len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526c418-a8c1-452f-af7c-8eaf2d7592aa",
   "metadata": {},
   "source": [
    "# model 0 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ccbc1b3-bcd6-473a-a3fa-90598722d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_1 = torch.load(\"best_model_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d22d007d-7851-4a6b-8360-7e9c130b9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/524\n",
      "1/524\n",
      "2/524\n",
      "3/524\n",
      "4/524\n",
      "5/524\n",
      "6/524\n",
      "7/524\n",
      "8/524\n",
      "9/524\n",
      "10/524\n",
      "11/524\n",
      "12/524\n",
      "13/524\n",
      "14/524\n",
      "15/524\n",
      "16/524\n",
      "17/524\n",
      "18/524\n",
      "19/524\n",
      "20/524\n",
      "21/524\n",
      "22/524\n",
      "23/524\n",
      "24/524\n",
      "25/524\n",
      "26/524\n",
      "27/524\n",
      "28/524\n",
      "29/524\n",
      "30/524\n",
      "31/524\n",
      "32/524\n",
      "33/524\n",
      "34/524\n",
      "35/524\n",
      "36/524\n",
      "37/524\n",
      "38/524\n",
      "39/524\n",
      "40/524\n",
      "41/524\n",
      "42/524\n",
      "43/524\n",
      "44/524\n",
      "45/524\n",
      "46/524\n",
      "47/524\n",
      "48/524\n",
      "49/524\n",
      "50/524\n",
      "51/524\n",
      "52/524\n",
      "53/524\n",
      "54/524\n",
      "55/524\n",
      "56/524\n",
      "57/524\n",
      "58/524\n",
      "59/524\n",
      "60/524\n",
      "61/524\n",
      "62/524\n",
      "63/524\n",
      "64/524\n",
      "65/524\n",
      "66/524\n",
      "67/524\n",
      "68/524\n",
      "69/524\n",
      "70/524\n",
      "71/524\n",
      "72/524\n",
      "73/524\n",
      "74/524\n",
      "75/524\n",
      "76/524\n",
      "77/524\n",
      "78/524\n",
      "79/524\n",
      "80/524\n",
      "81/524\n",
      "82/524\n",
      "83/524\n",
      "84/524\n",
      "85/524\n",
      "86/524\n",
      "87/524\n",
      "88/524\n",
      "89/524\n",
      "90/524\n",
      "91/524\n",
      "92/524\n",
      "93/524\n",
      "94/524\n",
      "95/524\n",
      "96/524\n",
      "97/524\n",
      "98/524\n",
      "99/524\n",
      "100/524\n",
      "101/524\n",
      "102/524\n",
      "103/524\n",
      "104/524\n",
      "105/524\n",
      "106/524\n",
      "107/524\n",
      "108/524\n",
      "109/524\n",
      "110/524\n",
      "111/524\n",
      "112/524\n",
      "113/524\n",
      "114/524\n",
      "115/524\n",
      "116/524\n",
      "117/524\n",
      "118/524\n",
      "119/524\n",
      "120/524\n",
      "121/524\n",
      "122/524\n",
      "123/524\n",
      "124/524\n",
      "125/524\n",
      "126/524\n",
      "127/524\n",
      "128/524\n",
      "129/524\n",
      "130/524\n",
      "131/524\n",
      "132/524\n",
      "133/524\n",
      "134/524\n",
      "135/524\n",
      "136/524\n",
      "137/524\n",
      "138/524\n",
      "139/524\n",
      "140/524\n",
      "141/524\n",
      "142/524\n",
      "143/524\n",
      "144/524\n",
      "145/524\n",
      "146/524\n",
      "147/524\n",
      "148/524\n",
      "149/524\n",
      "150/524\n",
      "151/524\n",
      "152/524\n",
      "153/524\n",
      "154/524\n",
      "155/524\n",
      "156/524\n",
      "157/524\n",
      "158/524\n",
      "159/524\n",
      "160/524\n",
      "161/524\n",
      "162/524\n",
      "163/524\n",
      "164/524\n",
      "165/524\n",
      "166/524\n",
      "167/524\n",
      "168/524\n",
      "169/524\n",
      "170/524\n",
      "171/524\n",
      "172/524\n",
      "173/524\n",
      "174/524\n",
      "175/524\n",
      "176/524\n",
      "177/524\n",
      "178/524\n",
      "179/524\n",
      "180/524\n",
      "181/524\n",
      "182/524\n",
      "183/524\n",
      "184/524\n",
      "185/524\n",
      "186/524\n",
      "187/524\n",
      "188/524\n",
      "189/524\n",
      "190/524\n",
      "191/524\n",
      "192/524\n",
      "193/524\n",
      "194/524\n",
      "195/524\n",
      "196/524\n",
      "197/524\n",
      "198/524\n",
      "199/524\n",
      "200/524\n",
      "201/524\n",
      "202/524\n",
      "203/524\n",
      "204/524\n",
      "205/524\n",
      "206/524\n",
      "207/524\n",
      "208/524\n",
      "209/524\n",
      "210/524\n",
      "211/524\n",
      "212/524\n",
      "213/524\n",
      "214/524\n",
      "215/524\n",
      "216/524\n",
      "217/524\n",
      "218/524\n",
      "219/524\n",
      "220/524\n",
      "221/524\n",
      "222/524\n",
      "223/524\n",
      "224/524\n",
      "225/524\n",
      "226/524\n",
      "227/524\n",
      "228/524\n",
      "229/524\n",
      "230/524\n",
      "231/524\n",
      "232/524\n",
      "233/524\n",
      "234/524\n",
      "235/524\n",
      "236/524\n",
      "237/524\n",
      "238/524\n",
      "239/524\n",
      "240/524\n",
      "241/524\n",
      "242/524\n",
      "243/524\n",
      "244/524\n",
      "245/524\n",
      "246/524\n",
      "247/524\n",
      "248/524\n",
      "249/524\n",
      "250/524\n",
      "251/524\n",
      "252/524\n",
      "253/524\n",
      "254/524\n",
      "255/524\n",
      "256/524\n",
      "257/524\n",
      "258/524\n",
      "259/524\n",
      "260/524\n",
      "261/524\n",
      "262/524\n",
      "263/524\n",
      "264/524\n",
      "265/524\n",
      "266/524\n",
      "267/524\n",
      "268/524\n",
      "269/524\n",
      "270/524\n",
      "271/524\n",
      "272/524\n",
      "273/524\n",
      "274/524\n",
      "275/524\n",
      "276/524\n",
      "277/524\n",
      "278/524\n",
      "279/524\n",
      "280/524\n",
      "281/524\n",
      "282/524\n",
      "283/524\n",
      "284/524\n",
      "285/524\n",
      "286/524\n",
      "287/524\n",
      "288/524\n",
      "289/524\n",
      "290/524\n",
      "291/524\n",
      "292/524\n",
      "293/524\n",
      "294/524\n",
      "295/524\n",
      "296/524\n",
      "297/524\n",
      "298/524\n",
      "299/524\n",
      "300/524\n",
      "301/524\n",
      "302/524\n",
      "303/524\n",
      "304/524\n",
      "305/524\n",
      "306/524\n",
      "307/524\n",
      "308/524\n",
      "309/524\n",
      "310/524\n",
      "311/524\n",
      "312/524\n",
      "313/524\n",
      "314/524\n",
      "315/524\n",
      "316/524\n",
      "317/524\n",
      "318/524\n",
      "319/524\n",
      "320/524\n",
      "321/524\n",
      "322/524\n",
      "323/524\n",
      "324/524\n",
      "325/524\n",
      "326/524\n",
      "327/524\n",
      "328/524\n",
      "329/524\n",
      "330/524\n",
      "331/524\n",
      "332/524\n",
      "333/524\n",
      "334/524\n",
      "335/524\n",
      "336/524\n",
      "337/524\n",
      "338/524\n",
      "339/524\n",
      "340/524\n",
      "341/524\n",
      "342/524\n",
      "343/524\n",
      "344/524\n",
      "345/524\n",
      "346/524\n",
      "347/524\n",
      "348/524\n",
      "349/524\n",
      "350/524\n",
      "351/524\n",
      "352/524\n",
      "353/524\n",
      "354/524\n",
      "355/524\n",
      "356/524\n",
      "357/524\n",
      "358/524\n",
      "359/524\n",
      "360/524\n",
      "361/524\n",
      "362/524\n",
      "363/524\n",
      "364/524\n",
      "365/524\n",
      "366/524\n",
      "367/524\n",
      "368/524\n",
      "369/524\n",
      "370/524\n",
      "371/524\n",
      "372/524\n",
      "373/524\n",
      "374/524\n",
      "375/524\n",
      "376/524\n",
      "377/524\n",
      "378/524\n",
      "379/524\n",
      "380/524\n",
      "381/524\n",
      "382/524\n",
      "383/524\n",
      "384/524\n",
      "385/524\n",
      "386/524\n",
      "387/524\n",
      "388/524\n",
      "389/524\n",
      "390/524\n",
      "391/524\n",
      "392/524\n",
      "393/524\n",
      "394/524\n",
      "395/524\n",
      "396/524\n",
      "397/524\n",
      "398/524\n",
      "399/524\n",
      "400/524\n",
      "401/524\n",
      "402/524\n",
      "403/524\n",
      "404/524\n",
      "405/524\n",
      "406/524\n",
      "407/524\n",
      "408/524\n",
      "409/524\n",
      "410/524\n",
      "411/524\n",
      "412/524\n",
      "413/524\n",
      "414/524\n",
      "415/524\n",
      "416/524\n",
      "417/524\n",
      "418/524\n",
      "419/524\n",
      "420/524\n",
      "421/524\n",
      "422/524\n",
      "423/524\n",
      "424/524\n",
      "425/524\n",
      "426/524\n",
      "427/524\n",
      "428/524\n",
      "429/524\n",
      "430/524\n",
      "431/524\n",
      "432/524\n",
      "433/524\n",
      "434/524\n",
      "435/524\n",
      "436/524\n",
      "437/524\n",
      "438/524\n",
      "439/524\n",
      "440/524\n",
      "441/524\n",
      "442/524\n",
      "443/524\n",
      "444/524\n",
      "445/524\n",
      "446/524\n",
      "447/524\n",
      "448/524\n",
      "449/524\n",
      "450/524\n",
      "451/524\n",
      "452/524\n",
      "453/524\n",
      "454/524\n",
      "455/524\n",
      "456/524\n",
      "457/524\n",
      "458/524\n",
      "459/524\n",
      "460/524\n",
      "461/524\n",
      "462/524\n",
      "463/524\n",
      "464/524\n",
      "465/524\n",
      "466/524\n",
      "467/524\n",
      "468/524\n",
      "469/524\n",
      "470/524\n",
      "471/524\n",
      "472/524\n",
      "473/524\n",
      "474/524\n",
      "475/524\n",
      "476/524\n",
      "477/524\n",
      "478/524\n",
      "479/524\n",
      "480/524\n",
      "481/524\n",
      "482/524\n",
      "483/524\n",
      "484/524\n",
      "485/524\n",
      "486/524\n",
      "487/524\n",
      "488/524\n",
      "489/524\n",
      "490/524\n",
      "491/524\n",
      "492/524\n",
      "493/524\n",
      "494/524\n",
      "495/524\n",
      "496/524\n",
      "497/524\n",
      "498/524\n",
      "499/524\n",
      "500/524\n",
      "501/524\n",
      "502/524\n",
      "503/524\n",
      "504/524\n",
      "505/524\n",
      "506/524\n",
      "507/524\n",
      "508/524\n",
      "509/524\n",
      "510/524\n",
      "511/524\n",
      "512/524\n",
      "513/524\n",
      "514/524\n",
      "515/524\n",
      "516/524\n",
      "517/524\n",
      "518/524\n",
      "519/524\n",
      "520/524\n",
      "521/524\n",
      "522/524\n",
      "523/524\n"
     ]
    }
   ],
   "source": [
    "h0_1.eval()\n",
    "word_error_rate1 = 0\n",
    "for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(test_dataLoader):\n",
    "    waveform = waveform.cuda()\n",
    "    input_len = input_len.cuda()\n",
    "    with torch.no_grad():\n",
    "        specs = encoder.compute_features(waveform)\n",
    "        targets = encoder.normalize(specs,input_len)\n",
    "        conv_1 = encoder.model.CNN.block_0.conv_1(targets)\n",
    "        norm_1 = encoder.model.CNN.block_0.norm_1(conv_1)\n",
    "        norm_1 =  norm_1.reshape( norm_1.shape[0], norm_1.shape[1],-1)\n",
    "        out = h0_1(norm_1)\n",
    "        trans = transcribe(out,input_len)\n",
    "        for i in range(len(trans)):\n",
    "            word_error_rate1 += wer(trans[i],transcript[i])\n",
    "        print(\"{}/{}\".format(j,len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd67f770-40f2-422f-9e73-23e5e1e79c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World error rate:0.06728262906765783\n"
     ]
    }
   ],
   "source": [
    "print(\"World error rate:{}\".format(word_error_rate1/5/len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b42910c4-3d0a-411c-9861-1f332bb43fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = torch.load(\"best_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1868a792-05bd-4c74-92ab-5ca63989275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/524\n",
      "2/524\n",
      "3/524\n",
      "4/524\n",
      "5/524\n",
      "6/524\n",
      "7/524\n",
      "8/524\n",
      "9/524\n",
      "10/524\n",
      "11/524\n",
      "12/524\n",
      "13/524\n",
      "14/524\n",
      "15/524\n",
      "16/524\n",
      "17/524\n",
      "18/524\n",
      "19/524\n",
      "20/524\n",
      "21/524\n",
      "22/524\n",
      "23/524\n",
      "24/524\n",
      "25/524\n",
      "26/524\n",
      "27/524\n",
      "28/524\n",
      "29/524\n",
      "30/524\n",
      "31/524\n",
      "32/524\n",
      "33/524\n",
      "34/524\n",
      "35/524\n",
      "36/524\n",
      "37/524\n",
      "38/524\n",
      "39/524\n",
      "40/524\n",
      "41/524\n",
      "42/524\n",
      "43/524\n",
      "44/524\n",
      "45/524\n",
      "46/524\n",
      "47/524\n",
      "48/524\n",
      "49/524\n",
      "50/524\n",
      "51/524\n",
      "52/524\n",
      "53/524\n",
      "54/524\n",
      "55/524\n",
      "56/524\n",
      "57/524\n",
      "58/524\n",
      "59/524\n",
      "60/524\n",
      "61/524\n",
      "62/524\n",
      "63/524\n",
      "64/524\n",
      "65/524\n",
      "66/524\n",
      "67/524\n",
      "68/524\n",
      "69/524\n",
      "70/524\n",
      "71/524\n",
      "72/524\n",
      "73/524\n",
      "74/524\n",
      "75/524\n",
      "76/524\n",
      "77/524\n",
      "78/524\n",
      "79/524\n",
      "80/524\n",
      "81/524\n",
      "82/524\n",
      "83/524\n",
      "84/524\n",
      "85/524\n",
      "86/524\n",
      "87/524\n",
      "88/524\n",
      "89/524\n",
      "90/524\n",
      "91/524\n",
      "92/524\n",
      "93/524\n",
      "94/524\n",
      "95/524\n",
      "96/524\n",
      "97/524\n",
      "98/524\n",
      "99/524\n",
      "100/524\n",
      "101/524\n",
      "102/524\n",
      "103/524\n",
      "104/524\n",
      "105/524\n",
      "106/524\n",
      "107/524\n",
      "108/524\n",
      "109/524\n",
      "110/524\n",
      "111/524\n",
      "112/524\n",
      "113/524\n",
      "114/524\n",
      "115/524\n",
      "116/524\n",
      "117/524\n",
      "118/524\n",
      "119/524\n",
      "120/524\n",
      "121/524\n",
      "122/524\n",
      "123/524\n",
      "124/524\n",
      "125/524\n",
      "126/524\n",
      "127/524\n",
      "128/524\n",
      "129/524\n",
      "130/524\n",
      "131/524\n",
      "132/524\n",
      "133/524\n",
      "134/524\n",
      "135/524\n",
      "136/524\n",
      "137/524\n",
      "138/524\n",
      "139/524\n",
      "140/524\n",
      "141/524\n",
      "142/524\n",
      "143/524\n",
      "144/524\n",
      "145/524\n",
      "146/524\n",
      "147/524\n",
      "148/524\n",
      "149/524\n",
      "150/524\n",
      "151/524\n",
      "152/524\n",
      "153/524\n",
      "154/524\n",
      "155/524\n",
      "156/524\n",
      "157/524\n",
      "158/524\n",
      "159/524\n",
      "160/524\n",
      "161/524\n",
      "162/524\n",
      "163/524\n",
      "164/524\n",
      "165/524\n",
      "166/524\n",
      "167/524\n",
      "168/524\n",
      "169/524\n",
      "170/524\n",
      "171/524\n",
      "172/524\n",
      "173/524\n",
      "174/524\n",
      "175/524\n",
      "176/524\n",
      "177/524\n",
      "178/524\n",
      "179/524\n",
      "180/524\n",
      "181/524\n",
      "182/524\n",
      "183/524\n",
      "184/524\n",
      "185/524\n",
      "186/524\n",
      "187/524\n",
      "188/524\n",
      "189/524\n",
      "190/524\n",
      "191/524\n",
      "192/524\n",
      "193/524\n",
      "194/524\n",
      "195/524\n",
      "196/524\n",
      "197/524\n",
      "198/524\n",
      "199/524\n",
      "200/524\n",
      "201/524\n",
      "202/524\n",
      "203/524\n",
      "204/524\n",
      "205/524\n",
      "206/524\n",
      "207/524\n",
      "208/524\n",
      "209/524\n",
      "210/524\n",
      "211/524\n",
      "212/524\n",
      "213/524\n",
      "214/524\n",
      "215/524\n",
      "216/524\n",
      "217/524\n",
      "218/524\n",
      "219/524\n",
      "220/524\n",
      "221/524\n",
      "222/524\n",
      "223/524\n",
      "224/524\n",
      "225/524\n",
      "226/524\n",
      "227/524\n",
      "228/524\n",
      "229/524\n",
      "230/524\n",
      "231/524\n",
      "232/524\n",
      "233/524\n",
      "234/524\n",
      "235/524\n",
      "236/524\n",
      "237/524\n",
      "238/524\n",
      "239/524\n",
      "240/524\n",
      "241/524\n",
      "242/524\n",
      "243/524\n",
      "244/524\n",
      "245/524\n",
      "246/524\n",
      "247/524\n",
      "248/524\n",
      "249/524\n",
      "250/524\n",
      "251/524\n",
      "252/524\n",
      "253/524\n",
      "254/524\n",
      "255/524\n",
      "256/524\n",
      "257/524\n",
      "258/524\n",
      "259/524\n",
      "260/524\n",
      "261/524\n",
      "262/524\n",
      "263/524\n",
      "264/524\n",
      "265/524\n",
      "266/524\n",
      "267/524\n",
      "268/524\n",
      "269/524\n",
      "270/524\n",
      "271/524\n",
      "272/524\n",
      "273/524\n",
      "274/524\n",
      "275/524\n",
      "276/524\n",
      "277/524\n",
      "278/524\n",
      "279/524\n",
      "280/524\n",
      "281/524\n",
      "282/524\n",
      "283/524\n",
      "284/524\n",
      "285/524\n",
      "286/524\n",
      "287/524\n",
      "288/524\n",
      "289/524\n",
      "290/524\n",
      "291/524\n",
      "292/524\n",
      "293/524\n",
      "294/524\n",
      "295/524\n",
      "296/524\n",
      "297/524\n",
      "298/524\n",
      "299/524\n",
      "300/524\n",
      "301/524\n",
      "302/524\n",
      "303/524\n",
      "304/524\n",
      "305/524\n",
      "306/524\n",
      "307/524\n",
      "308/524\n",
      "309/524\n",
      "310/524\n",
      "311/524\n",
      "312/524\n",
      "313/524\n",
      "314/524\n",
      "315/524\n",
      "316/524\n",
      "317/524\n",
      "318/524\n",
      "319/524\n",
      "320/524\n",
      "321/524\n",
      "322/524\n",
      "323/524\n",
      "324/524\n",
      "325/524\n",
      "326/524\n",
      "327/524\n",
      "328/524\n",
      "329/524\n",
      "330/524\n",
      "331/524\n",
      "332/524\n",
      "333/524\n",
      "334/524\n",
      "335/524\n",
      "336/524\n",
      "337/524\n",
      "338/524\n",
      "339/524\n",
      "340/524\n",
      "341/524\n",
      "342/524\n",
      "343/524\n",
      "344/524\n",
      "345/524\n",
      "346/524\n",
      "347/524\n",
      "348/524\n",
      "349/524\n",
      "350/524\n",
      "351/524\n",
      "352/524\n",
      "353/524\n",
      "354/524\n",
      "355/524\n",
      "356/524\n",
      "357/524\n",
      "358/524\n",
      "359/524\n",
      "360/524\n",
      "361/524\n",
      "362/524\n",
      "363/524\n",
      "364/524\n",
      "365/524\n",
      "366/524\n",
      "367/524\n",
      "368/524\n",
      "369/524\n",
      "370/524\n",
      "371/524\n",
      "372/524\n",
      "373/524\n",
      "374/524\n",
      "375/524\n",
      "376/524\n",
      "377/524\n",
      "378/524\n",
      "379/524\n",
      "380/524\n",
      "381/524\n",
      "382/524\n",
      "383/524\n",
      "384/524\n",
      "385/524\n",
      "386/524\n",
      "387/524\n",
      "388/524\n",
      "389/524\n",
      "390/524\n",
      "391/524\n",
      "392/524\n",
      "393/524\n",
      "394/524\n",
      "395/524\n",
      "396/524\n",
      "397/524\n",
      "398/524\n",
      "399/524\n",
      "400/524\n",
      "401/524\n",
      "402/524\n",
      "403/524\n",
      "404/524\n",
      "405/524\n",
      "406/524\n",
      "407/524\n",
      "408/524\n",
      "409/524\n",
      "410/524\n",
      "411/524\n",
      "412/524\n",
      "413/524\n",
      "414/524\n",
      "415/524\n",
      "416/524\n",
      "417/524\n",
      "418/524\n",
      "419/524\n",
      "420/524\n",
      "421/524\n",
      "422/524\n",
      "423/524\n",
      "424/524\n",
      "425/524\n",
      "426/524\n",
      "427/524\n",
      "428/524\n",
      "429/524\n",
      "430/524\n",
      "431/524\n",
      "432/524\n",
      "433/524\n",
      "434/524\n",
      "435/524\n",
      "436/524\n",
      "437/524\n",
      "438/524\n",
      "439/524\n",
      "440/524\n",
      "441/524\n",
      "442/524\n",
      "443/524\n",
      "444/524\n",
      "445/524\n",
      "446/524\n",
      "447/524\n",
      "448/524\n",
      "449/524\n",
      "450/524\n",
      "451/524\n",
      "452/524\n",
      "453/524\n",
      "454/524\n",
      "455/524\n",
      "456/524\n",
      "457/524\n",
      "458/524\n",
      "459/524\n",
      "460/524\n",
      "461/524\n",
      "462/524\n",
      "463/524\n",
      "464/524\n",
      "465/524\n",
      "466/524\n",
      "467/524\n",
      "468/524\n",
      "469/524\n",
      "470/524\n",
      "471/524\n",
      "472/524\n",
      "473/524\n",
      "474/524\n",
      "475/524\n",
      "476/524\n",
      "477/524\n",
      "478/524\n",
      "479/524\n",
      "480/524\n",
      "481/524\n",
      "482/524\n",
      "483/524\n",
      "484/524\n",
      "485/524\n",
      "486/524\n",
      "487/524\n",
      "488/524\n",
      "489/524\n",
      "490/524\n",
      "491/524\n",
      "492/524\n",
      "493/524\n",
      "494/524\n",
      "495/524\n",
      "496/524\n",
      "497/524\n",
      "498/524\n",
      "499/524\n",
      "500/524\n",
      "501/524\n",
      "502/524\n",
      "503/524\n",
      "504/524\n",
      "505/524\n",
      "506/524\n",
      "507/524\n",
      "508/524\n",
      "509/524\n",
      "510/524\n",
      "511/524\n",
      "512/524\n",
      "513/524\n",
      "514/524\n",
      "515/524\n",
      "516/524\n",
      "517/524\n",
      "518/524\n",
      "519/524\n",
      "520/524\n",
      "521/524\n",
      "522/524\n",
      "523/524\n",
      "524/524\n"
     ]
    }
   ],
   "source": [
    "h1.eval()\n",
    "word_error_rate2 = 0\n",
    "for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(test_dataLoader,start=1):\n",
    "    waveform = waveform.cuda()\n",
    "    input_len = input_len.cuda()\n",
    "    with torch.no_grad():\n",
    "        specs = encoder.compute_features(waveform)\n",
    "        targets = encoder.normalize(specs,input_len)\n",
    "        block_0 = encoder.model.CNN.block_0(targets)\n",
    "        block_1 = encoder.model.CNN.block_1( block_0)\n",
    "        block_1 = block_1.reshape(block_1.shape[0],block_1.shape[1],-1)\n",
    "        out = h1(block_1)\n",
    "        trans = transcribe(out,input_len)\n",
    "        for i in range(len(trans)):\n",
    "            word_error_rate2 += wer(trans[i],transcript[i])\n",
    "        print(\"{}/{}\".format(j,len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a6a2254d-8b6a-49b9-98fa-1866cd30563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World error rate:0.07345462276525248\n"
     ]
    }
   ],
   "source": [
    "print(\"World error rate:{}\".format(word_error_rate2/5/len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3263a2a2-e7e4-4e31-9962-323e19c8bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/524\n",
      "2/524\n",
      "3/524\n",
      "4/524\n",
      "5/524\n",
      "6/524\n",
      "7/524\n",
      "8/524\n",
      "9/524\n",
      "10/524\n",
      "11/524\n",
      "12/524\n",
      "13/524\n",
      "14/524\n",
      "15/524\n",
      "16/524\n",
      "17/524\n",
      "18/524\n",
      "19/524\n",
      "20/524\n",
      "21/524\n",
      "22/524\n",
      "23/524\n",
      "24/524\n",
      "25/524\n",
      "26/524\n",
      "27/524\n",
      "28/524\n",
      "29/524\n",
      "30/524\n",
      "31/524\n",
      "32/524\n",
      "33/524\n",
      "34/524\n",
      "35/524\n",
      "36/524\n",
      "37/524\n",
      "38/524\n",
      "39/524\n",
      "40/524\n",
      "41/524\n",
      "42/524\n",
      "43/524\n",
      "44/524\n",
      "45/524\n",
      "46/524\n",
      "47/524\n",
      "48/524\n",
      "49/524\n",
      "50/524\n",
      "51/524\n",
      "52/524\n",
      "53/524\n",
      "54/524\n",
      "55/524\n",
      "56/524\n",
      "57/524\n",
      "58/524\n",
      "59/524\n",
      "60/524\n",
      "61/524\n",
      "62/524\n",
      "63/524\n",
      "64/524\n",
      "65/524\n",
      "66/524\n",
      "67/524\n",
      "68/524\n",
      "69/524\n",
      "70/524\n",
      "71/524\n",
      "72/524\n",
      "73/524\n",
      "74/524\n",
      "75/524\n",
      "76/524\n",
      "77/524\n",
      "78/524\n",
      "79/524\n",
      "80/524\n",
      "81/524\n",
      "82/524\n",
      "83/524\n",
      "84/524\n",
      "85/524\n",
      "86/524\n",
      "87/524\n",
      "88/524\n",
      "89/524\n",
      "90/524\n",
      "91/524\n",
      "92/524\n",
      "93/524\n",
      "94/524\n",
      "95/524\n",
      "96/524\n",
      "97/524\n",
      "98/524\n",
      "99/524\n",
      "100/524\n",
      "101/524\n",
      "102/524\n",
      "103/524\n",
      "104/524\n",
      "105/524\n",
      "106/524\n",
      "107/524\n",
      "108/524\n",
      "109/524\n",
      "110/524\n",
      "111/524\n",
      "112/524\n",
      "113/524\n",
      "114/524\n",
      "115/524\n",
      "116/524\n",
      "117/524\n",
      "118/524\n",
      "119/524\n",
      "120/524\n",
      "121/524\n",
      "122/524\n",
      "123/524\n",
      "124/524\n",
      "125/524\n",
      "126/524\n",
      "127/524\n",
      "128/524\n",
      "129/524\n",
      "130/524\n",
      "131/524\n",
      "132/524\n",
      "133/524\n",
      "134/524\n",
      "135/524\n",
      "136/524\n",
      "137/524\n",
      "138/524\n",
      "139/524\n",
      "140/524\n",
      "141/524\n",
      "142/524\n",
      "143/524\n",
      "144/524\n",
      "145/524\n",
      "146/524\n",
      "147/524\n",
      "148/524\n",
      "149/524\n",
      "150/524\n",
      "151/524\n",
      "152/524\n",
      "153/524\n",
      "154/524\n",
      "155/524\n",
      "156/524\n",
      "157/524\n",
      "158/524\n",
      "159/524\n",
      "160/524\n",
      "161/524\n",
      "162/524\n",
      "163/524\n",
      "164/524\n",
      "165/524\n",
      "166/524\n",
      "167/524\n",
      "168/524\n",
      "169/524\n",
      "170/524\n",
      "171/524\n",
      "172/524\n",
      "173/524\n",
      "174/524\n",
      "175/524\n",
      "176/524\n",
      "177/524\n",
      "178/524\n",
      "179/524\n",
      "180/524\n",
      "181/524\n",
      "182/524\n",
      "183/524\n",
      "184/524\n",
      "185/524\n",
      "186/524\n",
      "187/524\n",
      "188/524\n",
      "189/524\n",
      "190/524\n",
      "191/524\n",
      "192/524\n",
      "193/524\n",
      "194/524\n",
      "195/524\n",
      "196/524\n",
      "197/524\n",
      "198/524\n",
      "199/524\n",
      "200/524\n",
      "201/524\n",
      "202/524\n",
      "203/524\n",
      "204/524\n",
      "205/524\n",
      "206/524\n",
      "207/524\n",
      "208/524\n",
      "209/524\n",
      "210/524\n",
      "211/524\n",
      "212/524\n",
      "213/524\n",
      "214/524\n",
      "215/524\n",
      "216/524\n",
      "217/524\n",
      "218/524\n",
      "219/524\n",
      "220/524\n",
      "221/524\n",
      "222/524\n",
      "223/524\n",
      "224/524\n",
      "225/524\n",
      "226/524\n",
      "227/524\n",
      "228/524\n",
      "229/524\n",
      "230/524\n",
      "231/524\n",
      "232/524\n",
      "233/524\n",
      "234/524\n",
      "235/524\n",
      "236/524\n",
      "237/524\n",
      "238/524\n",
      "239/524\n",
      "240/524\n",
      "241/524\n",
      "242/524\n",
      "243/524\n",
      "244/524\n",
      "245/524\n",
      "246/524\n",
      "247/524\n",
      "248/524\n",
      "249/524\n",
      "250/524\n",
      "251/524\n",
      "252/524\n",
      "253/524\n",
      "254/524\n",
      "255/524\n",
      "256/524\n",
      "257/524\n",
      "258/524\n",
      "259/524\n",
      "260/524\n",
      "261/524\n",
      "262/524\n",
      "263/524\n",
      "264/524\n",
      "265/524\n",
      "266/524\n",
      "267/524\n",
      "268/524\n",
      "269/524\n",
      "270/524\n",
      "271/524\n",
      "272/524\n",
      "273/524\n",
      "274/524\n",
      "275/524\n",
      "276/524\n",
      "277/524\n",
      "278/524\n",
      "279/524\n",
      "280/524\n",
      "281/524\n",
      "282/524\n",
      "283/524\n",
      "284/524\n",
      "285/524\n",
      "286/524\n",
      "287/524\n",
      "288/524\n",
      "289/524\n",
      "290/524\n",
      "291/524\n",
      "292/524\n",
      "293/524\n",
      "294/524\n",
      "295/524\n",
      "296/524\n",
      "297/524\n",
      "298/524\n",
      "299/524\n",
      "300/524\n",
      "301/524\n",
      "302/524\n",
      "303/524\n",
      "304/524\n",
      "305/524\n",
      "306/524\n",
      "307/524\n",
      "308/524\n",
      "309/524\n",
      "310/524\n",
      "311/524\n",
      "312/524\n",
      "313/524\n",
      "314/524\n",
      "315/524\n",
      "316/524\n",
      "317/524\n",
      "318/524\n",
      "319/524\n",
      "320/524\n",
      "321/524\n",
      "322/524\n",
      "323/524\n",
      "324/524\n",
      "325/524\n",
      "326/524\n",
      "327/524\n",
      "328/524\n",
      "329/524\n",
      "330/524\n",
      "331/524\n",
      "332/524\n",
      "333/524\n",
      "334/524\n",
      "335/524\n",
      "336/524\n",
      "337/524\n",
      "338/524\n",
      "339/524\n",
      "340/524\n",
      "341/524\n",
      "342/524\n",
      "343/524\n",
      "344/524\n",
      "345/524\n",
      "346/524\n",
      "347/524\n",
      "348/524\n",
      "349/524\n",
      "350/524\n",
      "351/524\n",
      "352/524\n",
      "353/524\n",
      "354/524\n",
      "355/524\n",
      "356/524\n",
      "357/524\n",
      "358/524\n",
      "359/524\n",
      "360/524\n",
      "361/524\n",
      "362/524\n",
      "363/524\n",
      "364/524\n",
      "365/524\n",
      "366/524\n",
      "367/524\n",
      "368/524\n",
      "369/524\n",
      "370/524\n",
      "371/524\n",
      "372/524\n",
      "373/524\n",
      "374/524\n",
      "375/524\n",
      "376/524\n",
      "377/524\n",
      "378/524\n",
      "379/524\n",
      "380/524\n",
      "381/524\n",
      "382/524\n",
      "383/524\n",
      "384/524\n",
      "385/524\n",
      "386/524\n",
      "387/524\n",
      "388/524\n",
      "389/524\n",
      "390/524\n",
      "391/524\n",
      "392/524\n",
      "393/524\n",
      "394/524\n",
      "395/524\n",
      "396/524\n",
      "397/524\n",
      "398/524\n",
      "399/524\n",
      "400/524\n",
      "401/524\n",
      "402/524\n",
      "403/524\n",
      "404/524\n",
      "405/524\n",
      "406/524\n",
      "407/524\n",
      "408/524\n",
      "409/524\n",
      "410/524\n",
      "411/524\n",
      "412/524\n",
      "413/524\n",
      "414/524\n",
      "415/524\n",
      "416/524\n",
      "417/524\n",
      "418/524\n",
      "419/524\n",
      "420/524\n",
      "421/524\n",
      "422/524\n",
      "423/524\n",
      "424/524\n",
      "425/524\n",
      "426/524\n",
      "427/524\n",
      "428/524\n",
      "429/524\n",
      "430/524\n",
      "431/524\n",
      "432/524\n",
      "433/524\n",
      "434/524\n",
      "435/524\n",
      "436/524\n",
      "437/524\n",
      "438/524\n",
      "439/524\n",
      "440/524\n",
      "441/524\n",
      "442/524\n",
      "443/524\n",
      "444/524\n",
      "445/524\n",
      "446/524\n",
      "447/524\n",
      "448/524\n",
      "449/524\n",
      "450/524\n",
      "451/524\n",
      "452/524\n",
      "453/524\n",
      "454/524\n",
      "455/524\n",
      "456/524\n",
      "457/524\n",
      "458/524\n",
      "459/524\n",
      "460/524\n",
      "461/524\n",
      "462/524\n",
      "463/524\n",
      "464/524\n",
      "465/524\n",
      "466/524\n",
      "467/524\n",
      "468/524\n",
      "469/524\n",
      "470/524\n",
      "471/524\n",
      "472/524\n",
      "473/524\n",
      "474/524\n",
      "475/524\n",
      "476/524\n",
      "477/524\n",
      "478/524\n",
      "479/524\n",
      "480/524\n",
      "481/524\n",
      "482/524\n",
      "483/524\n",
      "484/524\n",
      "485/524\n",
      "486/524\n",
      "487/524\n",
      "488/524\n",
      "489/524\n",
      "490/524\n",
      "491/524\n",
      "492/524\n",
      "493/524\n",
      "494/524\n",
      "495/524\n",
      "496/524\n",
      "497/524\n",
      "498/524\n",
      "499/524\n",
      "500/524\n",
      "501/524\n",
      "502/524\n",
      "503/524\n",
      "504/524\n",
      "505/524\n",
      "506/524\n",
      "507/524\n",
      "508/524\n",
      "509/524\n",
      "510/524\n",
      "511/524\n",
      "512/524\n",
      "513/524\n",
      "514/524\n",
      "515/524\n",
      "516/524\n",
      "517/524\n",
      "518/524\n",
      "519/524\n",
      "520/524\n",
      "521/524\n",
      "522/524\n",
      "523/524\n",
      "524/524\n"
     ]
    }
   ],
   "source": [
    "h1_1 = torch.load(\"best_model_11\")\n",
    "h1_1.eval()\n",
    "word_error_rate3 = 0\n",
    "for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(test_dataLoader,start=1):\n",
    "    waveform = waveform.cuda()\n",
    "    input_len = input_len.cuda()\n",
    "    with torch.no_grad():\n",
    "        specs = encoder.compute_features(waveform)\n",
    "        targets = encoder.normalize(specs,input_len)\n",
    "        block_0 = encoder.model.CNN.block_0(targets)\n",
    "        conv_1 = encoder.model.CNN.block_1.conv_1(block_0)\n",
    "        norm_1 = encoder.model.CNN.block_1.norm_1(conv_1)\n",
    "        norm_1 =  norm_1.reshape( norm_1.shape[0], norm_1.shape[1],-1)\n",
    "        out = h1_1(norm_1)\n",
    "        trans = transcribe(out,input_len)\n",
    "        for i in range(len(trans)):\n",
    "            word_error_rate3 += wer(trans[i],transcript[i])\n",
    "        print(\"{}/{}\".format(j,len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d444a7a3-3a87-492a-8ac0-901da768db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World error rate:0.06771345263494656\n"
     ]
    }
   ],
   "source": [
    "print(\"World error rate:{}\".format(word_error_rate3/5/len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6af97cd2-aa24-4a96-ade0-d6ece2cfde24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/524\n",
      "2/524\n",
      "3/524\n",
      "4/524\n",
      "5/524\n",
      "6/524\n",
      "7/524\n",
      "8/524\n",
      "9/524\n",
      "10/524\n",
      "11/524\n",
      "12/524\n",
      "13/524\n",
      "14/524\n",
      "15/524\n",
      "16/524\n",
      "17/524\n",
      "18/524\n",
      "19/524\n",
      "20/524\n",
      "21/524\n",
      "22/524\n",
      "23/524\n",
      "24/524\n",
      "25/524\n",
      "26/524\n",
      "27/524\n",
      "28/524\n",
      "29/524\n",
      "30/524\n",
      "31/524\n",
      "32/524\n",
      "33/524\n",
      "34/524\n",
      "35/524\n",
      "36/524\n",
      "37/524\n",
      "38/524\n",
      "39/524\n",
      "40/524\n",
      "41/524\n",
      "42/524\n",
      "43/524\n",
      "44/524\n",
      "45/524\n",
      "46/524\n",
      "47/524\n",
      "48/524\n",
      "49/524\n",
      "50/524\n",
      "51/524\n",
      "52/524\n",
      "53/524\n",
      "54/524\n",
      "55/524\n",
      "56/524\n",
      "57/524\n",
      "58/524\n",
      "59/524\n",
      "60/524\n",
      "61/524\n",
      "62/524\n",
      "63/524\n",
      "64/524\n",
      "65/524\n",
      "66/524\n",
      "67/524\n",
      "68/524\n",
      "69/524\n",
      "70/524\n",
      "71/524\n",
      "72/524\n",
      "73/524\n",
      "74/524\n",
      "75/524\n",
      "76/524\n",
      "77/524\n",
      "78/524\n",
      "79/524\n",
      "80/524\n",
      "81/524\n",
      "82/524\n",
      "83/524\n",
      "84/524\n",
      "85/524\n",
      "86/524\n",
      "87/524\n",
      "88/524\n",
      "89/524\n",
      "90/524\n",
      "91/524\n",
      "92/524\n",
      "93/524\n",
      "94/524\n",
      "95/524\n",
      "96/524\n",
      "97/524\n",
      "98/524\n",
      "99/524\n",
      "100/524\n",
      "101/524\n",
      "102/524\n",
      "103/524\n",
      "104/524\n",
      "105/524\n",
      "106/524\n",
      "107/524\n",
      "108/524\n",
      "109/524\n",
      "110/524\n",
      "111/524\n",
      "112/524\n",
      "113/524\n",
      "114/524\n",
      "115/524\n",
      "116/524\n",
      "117/524\n",
      "118/524\n",
      "119/524\n",
      "120/524\n",
      "121/524\n",
      "122/524\n",
      "123/524\n",
      "124/524\n",
      "125/524\n",
      "126/524\n",
      "127/524\n",
      "128/524\n",
      "129/524\n",
      "130/524\n",
      "131/524\n",
      "132/524\n",
      "133/524\n",
      "134/524\n",
      "135/524\n",
      "136/524\n",
      "137/524\n",
      "138/524\n",
      "139/524\n",
      "140/524\n",
      "141/524\n",
      "142/524\n",
      "143/524\n",
      "144/524\n",
      "145/524\n",
      "146/524\n",
      "147/524\n",
      "148/524\n",
      "149/524\n",
      "150/524\n",
      "151/524\n",
      "152/524\n",
      "153/524\n",
      "154/524\n",
      "155/524\n",
      "156/524\n",
      "157/524\n",
      "158/524\n",
      "159/524\n",
      "160/524\n",
      "161/524\n",
      "162/524\n",
      "163/524\n",
      "164/524\n",
      "165/524\n",
      "166/524\n",
      "167/524\n",
      "168/524\n",
      "169/524\n",
      "170/524\n",
      "171/524\n",
      "172/524\n",
      "173/524\n",
      "174/524\n",
      "175/524\n",
      "176/524\n",
      "177/524\n",
      "178/524\n",
      "179/524\n",
      "180/524\n",
      "181/524\n",
      "182/524\n",
      "183/524\n",
      "184/524\n",
      "185/524\n",
      "186/524\n",
      "187/524\n",
      "188/524\n",
      "189/524\n",
      "190/524\n",
      "191/524\n",
      "192/524\n",
      "193/524\n",
      "194/524\n",
      "195/524\n",
      "196/524\n",
      "197/524\n",
      "198/524\n",
      "199/524\n",
      "200/524\n",
      "201/524\n",
      "202/524\n",
      "203/524\n",
      "204/524\n",
      "205/524\n",
      "206/524\n",
      "207/524\n",
      "208/524\n",
      "209/524\n",
      "210/524\n",
      "211/524\n",
      "212/524\n",
      "213/524\n",
      "214/524\n",
      "215/524\n",
      "216/524\n",
      "217/524\n",
      "218/524\n",
      "219/524\n",
      "220/524\n",
      "221/524\n",
      "222/524\n",
      "223/524\n",
      "224/524\n",
      "225/524\n",
      "226/524\n",
      "227/524\n",
      "228/524\n",
      "229/524\n",
      "230/524\n",
      "231/524\n",
      "232/524\n",
      "233/524\n",
      "234/524\n",
      "235/524\n",
      "236/524\n",
      "237/524\n",
      "238/524\n",
      "239/524\n",
      "240/524\n",
      "241/524\n",
      "242/524\n",
      "243/524\n",
      "244/524\n",
      "245/524\n",
      "246/524\n",
      "247/524\n",
      "248/524\n",
      "249/524\n",
      "250/524\n",
      "251/524\n",
      "252/524\n",
      "253/524\n",
      "254/524\n",
      "255/524\n",
      "256/524\n",
      "257/524\n",
      "258/524\n",
      "259/524\n",
      "260/524\n",
      "261/524\n",
      "262/524\n",
      "263/524\n",
      "264/524\n",
      "265/524\n",
      "266/524\n",
      "267/524\n",
      "268/524\n",
      "269/524\n",
      "270/524\n",
      "271/524\n",
      "272/524\n",
      "273/524\n",
      "274/524\n",
      "275/524\n",
      "276/524\n",
      "277/524\n",
      "278/524\n",
      "279/524\n",
      "280/524\n",
      "281/524\n",
      "282/524\n",
      "283/524\n",
      "284/524\n",
      "285/524\n",
      "286/524\n",
      "287/524\n",
      "288/524\n",
      "289/524\n",
      "290/524\n",
      "291/524\n",
      "292/524\n",
      "293/524\n",
      "294/524\n",
      "295/524\n",
      "296/524\n",
      "297/524\n",
      "298/524\n",
      "299/524\n",
      "300/524\n",
      "301/524\n",
      "302/524\n",
      "303/524\n",
      "304/524\n",
      "305/524\n",
      "306/524\n",
      "307/524\n",
      "308/524\n",
      "309/524\n",
      "310/524\n",
      "311/524\n",
      "312/524\n",
      "313/524\n",
      "314/524\n",
      "315/524\n",
      "316/524\n",
      "317/524\n",
      "318/524\n",
      "319/524\n",
      "320/524\n",
      "321/524\n",
      "322/524\n",
      "323/524\n",
      "324/524\n",
      "325/524\n",
      "326/524\n",
      "327/524\n",
      "328/524\n",
      "329/524\n",
      "330/524\n",
      "331/524\n",
      "332/524\n",
      "333/524\n",
      "334/524\n",
      "335/524\n",
      "336/524\n",
      "337/524\n",
      "338/524\n",
      "339/524\n",
      "340/524\n",
      "341/524\n",
      "342/524\n",
      "343/524\n",
      "344/524\n",
      "345/524\n",
      "346/524\n",
      "347/524\n",
      "348/524\n",
      "349/524\n",
      "350/524\n",
      "351/524\n",
      "352/524\n",
      "353/524\n",
      "354/524\n",
      "355/524\n",
      "356/524\n",
      "357/524\n",
      "358/524\n",
      "359/524\n",
      "360/524\n",
      "361/524\n",
      "362/524\n",
      "363/524\n",
      "364/524\n",
      "365/524\n",
      "366/524\n",
      "367/524\n",
      "368/524\n",
      "369/524\n",
      "370/524\n",
      "371/524\n",
      "372/524\n",
      "373/524\n",
      "374/524\n",
      "375/524\n",
      "376/524\n",
      "377/524\n",
      "378/524\n",
      "379/524\n",
      "380/524\n",
      "381/524\n",
      "382/524\n",
      "383/524\n",
      "384/524\n",
      "385/524\n",
      "386/524\n",
      "387/524\n",
      "388/524\n",
      "389/524\n",
      "390/524\n",
      "391/524\n",
      "392/524\n",
      "393/524\n",
      "394/524\n",
      "395/524\n",
      "396/524\n",
      "397/524\n",
      "398/524\n",
      "399/524\n",
      "400/524\n",
      "401/524\n",
      "402/524\n",
      "403/524\n",
      "404/524\n",
      "405/524\n",
      "406/524\n",
      "407/524\n",
      "408/524\n",
      "409/524\n",
      "410/524\n",
      "411/524\n",
      "412/524\n",
      "413/524\n",
      "414/524\n",
      "415/524\n",
      "416/524\n",
      "417/524\n",
      "418/524\n",
      "419/524\n",
      "420/524\n",
      "421/524\n",
      "422/524\n",
      "423/524\n",
      "424/524\n",
      "425/524\n",
      "426/524\n",
      "427/524\n",
      "428/524\n",
      "429/524\n",
      "430/524\n",
      "431/524\n",
      "432/524\n",
      "433/524\n",
      "434/524\n",
      "435/524\n",
      "436/524\n",
      "437/524\n",
      "438/524\n",
      "439/524\n",
      "440/524\n",
      "441/524\n",
      "442/524\n",
      "443/524\n",
      "444/524\n",
      "445/524\n",
      "446/524\n",
      "447/524\n",
      "448/524\n",
      "449/524\n",
      "450/524\n",
      "451/524\n",
      "452/524\n",
      "453/524\n",
      "454/524\n",
      "455/524\n",
      "456/524\n",
      "457/524\n",
      "458/524\n",
      "459/524\n",
      "460/524\n",
      "461/524\n",
      "462/524\n",
      "463/524\n",
      "464/524\n",
      "465/524\n",
      "466/524\n",
      "467/524\n",
      "468/524\n",
      "469/524\n",
      "470/524\n",
      "471/524\n",
      "472/524\n",
      "473/524\n",
      "474/524\n",
      "475/524\n",
      "476/524\n",
      "477/524\n",
      "478/524\n",
      "479/524\n",
      "480/524\n",
      "481/524\n",
      "482/524\n",
      "483/524\n",
      "484/524\n",
      "485/524\n",
      "486/524\n",
      "487/524\n",
      "488/524\n",
      "489/524\n",
      "490/524\n",
      "491/524\n",
      "492/524\n",
      "493/524\n",
      "494/524\n",
      "495/524\n",
      "496/524\n",
      "497/524\n",
      "498/524\n",
      "499/524\n",
      "500/524\n",
      "501/524\n",
      "502/524\n",
      "503/524\n",
      "504/524\n",
      "505/524\n",
      "506/524\n",
      "507/524\n",
      "508/524\n",
      "509/524\n",
      "510/524\n",
      "511/524\n",
      "512/524\n",
      "513/524\n",
      "514/524\n",
      "515/524\n",
      "516/524\n",
      "517/524\n",
      "518/524\n",
      "519/524\n",
      "520/524\n",
      "521/524\n",
      "522/524\n",
      "523/524\n",
      "524/524\n"
     ]
    }
   ],
   "source": [
    "word_error_rate4 = 0\n",
    "for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(test_dataLoader,start=1):\n",
    "    waveform = waveform.cuda()\n",
    "    input_len = input_len.cuda()\n",
    "    with torch.no_grad():\n",
    "        trans,_ = model.transcribe_batch(waveform,input_len)\n",
    "        for i in range(len(trans)):\n",
    "            word_error_rate4 += wer(trans[i],transcript[i])\n",
    "        print(\"{}/{}\".format(j,len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "32308559-c52c-448e-bd97-cb4c5af27d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World error rate:0.06677564656410001\n"
     ]
    }
   ],
   "source": [
    "print(\"World error rate:{}\".format(word_error_rate4/5/len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4a30c3a0-907a-49e8-aeaa-7fffe8ea19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "score, prediction =verification.verify_files(\"speechbrain/spkrec-ecapa-voxceleb/example1.wav\", \"speechbrain/spkrec-ecapa-voxceleb/example2.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "60e244cf-6550-41d9-a5ab-c8cf75260538",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav,sr = torchaudio.load(\"example1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7618b956-3225-4fad-b25b-4447faa1b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "751b5876-b587-4654-ad1e-9553a6b8667e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 52173])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(wav.reshape(-1))\n",
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "561924e5-b95e-4120-a15d-e0c747e2254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = wav.cuda()\n",
    "input_len = torch.FloatTensor([1.0]).cuda()\n",
    "with torch.no_grad():\n",
    "    specs = encoder.compute_features(wav)\n",
    "    targets = encoder.normalize(specs,input_len)\n",
    "    block_0 = encoder.model.CNN.block_0(targets)\n",
    "    block_0 = block_0.reshape(block_0.shape[0],block_0.shape[1],-1)\n",
    "    out = h0(block_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0b0d4525-2546-42cc-9697-007a3ea259e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.6289, -3.8508, -3.6348,  ..., -3.0047, -2.6919, -3.0465],\n",
       "         [-2.6995, -2.9194, -2.5090,  ..., -2.2184, -2.2175, -2.6312],\n",
       "         [-1.9627, -1.8744, -1.7339,  ..., -1.8063, -2.1418, -2.3433],\n",
       "         ...,\n",
       "         [-2.0504, -1.7467, -1.8110,  ..., -1.4124, -1.2631, -1.5580],\n",
       "         [-2.0562, -1.5912, -1.7146,  ..., -1.0853, -1.1753, -1.4252],\n",
       "         [-1.7762, -1.3342, -1.3647,  ..., -0.7943, -1.0362, -0.8829]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape\n",
    "out.permute([0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "06b47b0e-f7b7-45f0-a2a0-e7ee3d84cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchaudio.transforms.GriffinLim(n_fft=78)\n",
    "# transform = torchaudio.transforms.InverseSpectrogram(win_length=400,hop_length=10,window_fn=torch.hamming_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "455d23f4-3b28-436e-abdc-393126ecf300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torchaudio/functional/functional.py:180: UserWarning: The use of pseudo complex type in inverse_spectrogram is now deprecated. Please migrate to native complex type by using a complex tensor as input. If the input is generated via spectrogram() function or transform, please use return_complex=True as an argument to that function. Please refer to https://github.com/pytorch/audio/issues/1337 for more details about torchaudio's plan to migrate to native complex type.\n",
      "  \"The use of pseudo complex type in inverse_spectrogram is now deprecated. \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor must have a last dimension of size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-9ee44d2e5249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout_wav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torchaudio/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, spectrogram, length)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monesided\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torchaudio/functional/functional.py\u001b[0m in \u001b[0;36minverse_spectrogram\u001b[0;34m(spectrogram, length, pad, window, n_fft, hop_length, win_length, normalized, center, pad_mode, onesided)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;34m\"for more details about torchaudio's plan to migrate to native complex type.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         )\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor must have a last dimension of size 2"
     ]
    }
   ],
   "source": [
    "out_wav = transform(out.permute([0,2,1]).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbd400-9f53-4de0-9970-955ea8111e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12714])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbf4622f350>]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(out_wav.shape)\n",
    "plt.plot(out_wav.reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "24b9fd9c-75e7-4f23-81b8-80e880046403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROMPTLY']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trans,_ = model.transcribe_batch(out_wav.cuda(),torch.FloatTensor([1.0]).cuda())\n",
    "    print(trans)\n",
    "#     for i in range(len(trans)):\n",
    "        \n",
    "#     print(\"{}/{}\".format(j,len(test_dataLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d96e9469-2dd2-40c5-a1b3-929794e62909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE BIRCH CANOE SLID ON THE SMOOTH PLANKS']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trans,_ = model.transcribe_batch(wav.cuda(),torch.FloatTensor([1.0]).cuda())\n",
    "    print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1afd9ad0-cb2e-4f0a-80d4-399acadd1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_1 = torch.load(\"best_model_11\")\n",
    "h1_1.eval()\n",
    "word_error_rate3 = 0\n",
    "for j,(waveform, input_len ,sample_rate, transcript, speaker_id) in enumerate(test_dataLoader,start=1):\n",
    "    waveform = waveform.cuda()\n",
    "    input_len = input_len.cuda()\n",
    "    with torch.no_grad():\n",
    "        specs = encoder.compute_features(waveform)\n",
    "        targets = encoder.normalize(specs,input_len)\n",
    "        block_0 = encoder.model.CNN.block_0(targets)\n",
    "        conv_1 = encoder.model.CNN.block_1.conv_1(block_0)\n",
    "        norm_1 = encoder.model.CNN.block_1.norm_1(conv_1)\n",
    "        norm_1 =  norm_1.reshape( norm_1.shape[0], norm_1.shape[1],-1)\n",
    "        out = h1_1(norm_1)\n",
    "        trans = transcribe(out,input_len)\n",
    "        for i in range(len(trans)):\n",
    "            word_error_rate3 += wer(trans[i],transcript[i])\n",
    "        # print(\"{}/{}\".format(j,len(test_dataLoader)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bc49520c-6db4-4e25-b28b-5720228ed9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1044, 40])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0fa99f99-846f-4f01-aba1-16ba3d0d58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_wav = transform(torch.abs(specs.permute([0,2,1]).cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3d419dc9-a4b5-4d90-b2bd-25228507f108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 40677])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "28ad7698-6f34-4c89-b11d-8b98535ac555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SYMPATHY ACCORDINGLY', 'ACCORDING TO SYMPATHY', 'ACCORDING TO DRINK', \"IT'S ABSOLUTELY ABSOLUTELY\", \"IT'S ABSOLUTELY DESERTED\"]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trans,_ = model.transcribe_batch(out_wav.cuda(),input_len.cuda())\n",
    "    print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1b80234e-9566-4c4a-9bad-109e86fc1796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HE HOPED THERE WOULD BE STEW FOR DINNER TURNIPS AND CARROTS AND BRUISED POTATOES AND FAT MUTTON PIECES TO BE LADLED OUT IN THICK PEPPERED FLOUR FAT AND SAUCE', 'STUFFED INTO YOU HIS BELLY COUNSELLED I', 'AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS', 'OH BERTIE ANY GOOD IN YOUR MIND', 'NUMBER DEN FRESH NELLIE IS WAITING ON YOU GOOD NIGHT HUSBAND']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trans,_ = model.transcribe_batch(waveform.cuda(),input_len.cuda())\n",
    "    print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13171d6-062b-4dde-97f9-f7eaae0b5416",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-78ae3478508f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fc406cb9-e840-4795-a55f-d6b0e790e46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filterbank()"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.compute_features.compute_fbanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5ac669-0b21-4213-9c8f-5f14887744fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LengthsCapableSequential(\n",
       "  (compute_features): Fbank(\n",
       "    (compute_STFT): STFT()\n",
       "    (compute_fbanks): Filterbank()\n",
       "    (compute_deltas): Deltas()\n",
       "    (context_window): ContextWindow()\n",
       "  )\n",
       "  (normalize): InputNormalization()\n",
       "  (model): CRDNN(\n",
       "    (CNN): Sequential(\n",
       "      (block_0): CNN_Block(\n",
       "        (conv_1): Conv2d(\n",
       "          (conv): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (norm_1): LayerNorm(\n",
       "          (norm): LayerNorm((40, 128), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (act_1): LeakyReLU(negative_slope=0.01)\n",
       "        (conv_2): Conv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (norm_2): LayerNorm(\n",
       "          (norm): LayerNorm((40, 128), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (act_2): LeakyReLU(negative_slope=0.01)\n",
       "        (pooling): Pooling1d(\n",
       "          (pool_layer): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "        )\n",
       "        (drop): Dropout2d(\n",
       "          (drop): Dropout2d(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (block_1): CNN_Block(\n",
       "        (conv_1): Conv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (norm_1): LayerNorm(\n",
       "          (norm): LayerNorm((20, 256), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (act_1): LeakyReLU(negative_slope=0.01)\n",
       "        (conv_2): Conv2d(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (norm_2): LayerNorm(\n",
       "          (norm): LayerNorm((20, 256), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (act_2): LeakyReLU(negative_slope=0.01)\n",
       "        (pooling): Pooling1d(\n",
       "          (pool_layer): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "        )\n",
       "        (drop): Dropout2d(\n",
       "          (drop): Dropout2d(p=0.15, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (time_pooling): Pooling1d(\n",
       "      (pool_layer): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    )\n",
       "    (RNN): LSTM(\n",
       "      (rnn): LSTM(2560, 1024, num_layers=4, batch_first=True, dropout=0.15, bidirectional=True)\n",
       "    )\n",
       "    (DNN): Sequential(\n",
       "      (block_0): DNN_Block(\n",
       "        (linear): Linear(\n",
       "          (w): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): BatchNorm1d(\n",
       "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (dropout): Dropout(p=0.15, inplace=False)\n",
       "      )\n",
       "      (block_1): DNN_Block(\n",
       "        (linear): Linear(\n",
       "          (w): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): BatchNorm1d(\n",
       "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (dropout): Dropout(p=0.15, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133aab3b-4936-403a-a629-764c134af0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc1d3c-9432-42f1-ac7a-ffdbcbed6630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
